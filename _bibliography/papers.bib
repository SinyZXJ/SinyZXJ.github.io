---
---

@inproceedings{zhang2024assembly,
  title={Learning-based Stage Verification System in Manual Assembly Scenarios (Oral)},
  booktitle={International Conference on Smart Assembly and Manufacturing},
  author={Zhang, Xingjian and Duan, Yutong and Chen, Zaishu},
  year={2024},
  publisher={Lecture Notes in Mechanical Engineering},
  preview={LAVIS.png},
  abstract={In the context of Industry 4.0, effective monitoring of multiple targets and states during assembly processes is crucial, particularly when constrained to using only visual sensors. Traditional methods often rely on either multiple sensor types or complex hardware setups to achieve high accuracy in monitoring, which can be cost-prohibitive and difficult to implement in dynamic industrial environments. This study presents a novel approach that leverages multiple machine learning models to achieve precise monitoring under the limitation of using a minimal number of visual sensors. By integrating state information from identical timestamps, our method detects and confirms the current stage of the assembly process with an average accuracy exceeding 92%. Furthermore, our approach surpasses conventional methods by offering enhanced error detection and visualization capabilities, providing real-time, actionable guidance to operators. This not only improves the accuracy and efficiency of assembly monitoring but also reduces dependency on expensive hardware solutions, making it a more practical choice for modern industrial applications. },
  pdf={},
  abbr={ICSAM'24},
  selected={true}
}

@inproceedings{rui2025ipp,
  title={Attention-based Learning for 3D Informative Path Planning (submitted)},
  author={Zhao*, Rui and Zhang*, Xingjian and Cao, Yuhong and Wang, Yizhuo and Sartoretti, Guillaume},
  booktitle={IEEE International Conference on Robotics and Automation},
  abstract={In this work, we propose an attention-based deep reinforcement learning approach to address the adaptive informative path planning (IPP) problem in 3D space, where an aerial robot equipped with a downward-facing sensor must dynamically adjust its 3D position to balance sensing footprint and accuracy, and finally obtain a high-quality belief of an underlying field of interest over a given domain (e.g., presence of specific plants, hazardous gas, geological structures, etc.). In adaptive IPP tasks, the agent is tasked with maximizing information collected under time/distance constraints, continuously adapting its path based on newly acquired sensor data. To this end, we leverage attention mechanisms for their strong ability to capture global spatial dependencies across large action spaces, allowing the agent to learn an implicit estimation of environmental transitions. Our model builds a contextual belief representation over the entire domain, guiding sequential movement decisions that optimize both short- and long-term search objectives. Comparative evaluations against state-of-the-art planners demonstrate that our approach significantly reduces environmental uncertainty within constrained budgets, thus allowing the agent to effectively balance exploration and exploitation. We further show our model generalizes well to environments of varying sizes, highlighting its potential for many real-world applications.},
  year={2026},
  publisher={IEEE},
  preview={3DIPP.gif},
  pdf={https://arxiv.org/abs/2506.08434},
  abbr={ICUAS'26},
  html={https://drive.google.com/file/d/1pQsMaM-mOyKm4Pc_zlZDgCacbkW16XDt/view?usp=sharing},
  selected={true}
}

@inproceedings{zhang2025compass,
  title={COMPASS: Cooperative Multi-Agent Persistent Monitoring using Spatio-Temporal Attention Network (Oral)},
  author={Zhang, Xingjian and Wang, Yizhuo and Sartoretti, Guillaume},
  booktitle={IEEE Multi-Robot Systems},
  year={2025},
  abstract={This work introduces a multi-agent deep reinforcement learning (MARL) framework for persistent monitoring and informative path planning (IPP) of dynamically evolving targets using unmanned agents. Addressing the challenges inherent in real-time multi-target tracking within uncertain environments, we propose a novel spatio-temporal attention network that integrates Gaussian Processes (GPs) for modeling and predicting target distributions. The developed approach discretizes the monitoring environment into graph structures, enabling agents to leverage historical spatial and temporal information efficiently. Our MARL approach employs a Proximal Policy Optimization (PPO) algorithm within a Centralized Training Decentralized Execution (CTDE) paradigm, ensuring effective cooperation among agents while maintaining autonomy in decision-making during execution. We further introduce an adaptive reward mechanism based on uncertainty reduction, explicitly penalizing redundant observations to encourage diversified exploration and cooperative behavior. Experimental results demonstrate that our method significantly improves information gain and reduces uncertainty in dynamic, multi-target scenarios, showcasing superior collaboration capabilities among agents compared to baseline methods.},
  pdf={https://arxiv.org/abs/2507.16306},
  html={https://drive.google.com/file/d/1FZAgR7ua5FmkHDFahToV7COtZS7R2sPy/view?usp=sharing},
  abbr={MRS'25},
  preview={COMPASS.gif},
  award={Best Paper Finalist},
  selected={true}
}

@inproceedings{zhang2026reason,
  title={REASON: REinforced Agent Symbolic reasoning for Object-centric maNipulation (Manuscript in preparation)},
  author={Zhang, Xingjian and Feng, Zeyu},
  booktitle={International Conference on Machine Learning},
  year={2026},
  abbr={ICLR'26},
  preview={reason.gif},
  abstract={In this work, we introduce REASON, a neuro-symbolic framework that unifies symbolic reasoning and neural control for object-centric manipulation. Leveraging visual language models (VLMs), REASON extracts structured symbolic predicates from raw visual scenes. These symbolic representations are processed alongside pixel-based observations to jointly train a hybrid policy that blends interpretable logic-based reasoning with reactive neural control. By decoupling high-level decision-making from low-level execution, REASON enables agents to generate explainable and transferable plans that can be executed by downstream motion planners. We demonstrate that REASON not only improves performance and generalization in manipulation tasks but also provides transparent decision pathways grounded in symbolic logic.}
}

@inproceedings{zhang2026vrs,
  title={Visual Room Segmentation on 3D Scene Graphs (Manuscript in preparation)},
  author={Zhang, Xingjian and Rajat Talak},
  booktitle={International Conference on Intelligent Robots and Systems},
  year={2026},
  abbr={IROS'26},
  abstract={In this work, we introduce VRS, a novel approach to visual room segmentation on 3D scene graphs. Coming soon.}
}
